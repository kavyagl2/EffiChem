{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASE MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATASET ISPECT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- fart_test ---\n",
      "Shape: (2254, 7)\n",
      "Columns: ['Unnamed: 0', 'Canonicalized SMILES', 'Standardized SMILES', 'Canonicalized Taste', 'Original Labels', 'Source', 'is_multiclass']\n",
      "\n",
      "Missing Values:\n",
      " Unnamed: 0              0\n",
      "Canonicalized SMILES    0\n",
      "Standardized SMILES     0\n",
      "Canonicalized Taste     0\n",
      "Original Labels         0\n",
      "Source                  0\n",
      "is_multiclass           0\n",
      "dtype: int64\n",
      "\n",
      "Data Types:\n",
      " Unnamed: 0               int64\n",
      "Canonicalized SMILES    object\n",
      "Standardized SMILES     object\n",
      "Canonicalized Taste     object\n",
      "Original Labels         object\n",
      "Source                  object\n",
      "is_multiclass            int64\n",
      "dtype: object\n",
      "\n",
      "Summary Statistics:\n",
      "          Unnamed: 0  is_multiclass\n",
      "count   2254.000000         2254.0\n",
      "mean    7048.832298            0.0\n",
      "std     4101.425559            0.0\n",
      "min        3.000000            0.0\n",
      "25%     3463.000000            0.0\n",
      "50%     7115.000000            0.0\n",
      "75%    10643.750000            0.0\n",
      "max    14152.000000            0.0\n",
      "\n",
      "Duplicate Rows: 0\n",
      "\n",
      "--- fart_eval ---\n",
      "Shape: (2254, 7)\n",
      "Columns: ['Unnamed: 0', 'Canonicalized SMILES', 'Standardized SMILES', 'Canonicalized Taste', 'Original Labels', 'Source', 'is_multiclass']\n",
      "\n",
      "Missing Values:\n",
      " Unnamed: 0              0\n",
      "Canonicalized SMILES    0\n",
      "Standardized SMILES     0\n",
      "Canonicalized Taste     0\n",
      "Original Labels         0\n",
      "Source                  0\n",
      "is_multiclass           0\n",
      "dtype: int64\n",
      "\n",
      "Data Types:\n",
      " Unnamed: 0               int64\n",
      "Canonicalized SMILES    object\n",
      "Standardized SMILES     object\n",
      "Canonicalized Taste     object\n",
      "Original Labels         object\n",
      "Source                  object\n",
      "is_multiclass            int64\n",
      "dtype: object\n",
      "\n",
      "Summary Statistics:\n",
      "          Unnamed: 0  is_multiclass\n",
      "count   2254.000000         2254.0\n",
      "mean    7034.749335            0.0\n",
      "std     4076.056215            0.0\n",
      "min        0.000000            0.0\n",
      "25%     3543.000000            0.0\n",
      "50%     7070.000000            0.0\n",
      "75%    10443.500000            0.0\n",
      "max    14153.000000            0.0\n",
      "\n",
      "Duplicate Rows: 0\n",
      "\n",
      "--- fart_train ---\n",
      "Shape: (10517, 7)\n",
      "Columns: ['Unnamed: 0', 'Canonicalized SMILES', 'Standardized SMILES', 'Canonicalized Taste', 'Original Labels', 'Source', 'is_multiclass']\n",
      "\n",
      "Missing Values:\n",
      " Unnamed: 0              0\n",
      "Canonicalized SMILES    0\n",
      "Standardized SMILES     0\n",
      "Canonicalized Taste     0\n",
      "Original Labels         0\n",
      "Source                  0\n",
      "is_multiclass           0\n",
      "dtype: int64\n",
      "\n",
      "Data Types:\n",
      " Unnamed: 0               int64\n",
      "Canonicalized SMILES    object\n",
      "Standardized SMILES     object\n",
      "Canonicalized Taste     object\n",
      "Original Labels         object\n",
      "Source                  object\n",
      "is_multiclass            int64\n",
      "dtype: object\n",
      "\n",
      "Summary Statistics:\n",
      "          Unnamed: 0  is_multiclass\n",
      "count  10517.000000   10517.000000\n",
      "mean    5258.000000       0.082818\n",
      "std     3036.140725       0.275620\n",
      "min        0.000000       0.000000\n",
      "25%     2629.000000       0.000000\n",
      "50%     5258.000000       0.000000\n",
      "75%     7887.000000       0.000000\n",
      "max    10516.000000       1.000000\n",
      "\n",
      "Duplicate Rows: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "file_paths = {\n",
    "    \"fart_test\": \"./fart_test.csv\",\n",
    "    \"fart_eval\": \"./fart_val.csv\",\n",
    "    \"fart_train\": \"./fart_train.csv\"\n",
    "}\n",
    "\n",
    "datasets = {name: pd.read_csv(path) for name, path in file_paths.items()}\n",
    "\n",
    "def summarize_dataset(name, df):\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(\"Columns:\", df.columns.tolist())\n",
    "    print(\"\\nMissing Values:\\n\", df.isnull().sum())\n",
    "    print(\"\\nData Types:\\n\", df.dtypes)\n",
    "    print(\"\\nSummary Statistics:\\n\", df.describe())\n",
    "    print(\"\\nDuplicate Rows:\", df.duplicated().sum())\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    summarize_dataset(name, df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EMBEDDINGS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {name: pd.read_csv(path) for name, path in file_paths.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configurations (Only Base Models for Now)\n",
    "models_info = {\n",
    "    \"ChemBERTa_Base\": {\n",
    "        \"tokenizer\": \"seyonec/SMILES_tokenized_PubChem_shard00_160k\",\n",
    "        \"model\": \"seyonec/SMILES_tokenized_PubChem_shard00_160k\"\n",
    "    },\n",
    "    \"MolFormer_Base\": {\n",
    "        \"tokenizer\": \"ibm-research/MoLFormer-XL-both-10pct\",\n",
    "        \"model\": \"ibm-research/MoLFormer-XL-both-10pct\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "        model = AutoModel.from_pretrained(model_name, trust_remote_code=True)\n",
    "        model.eval()  # Set to evaluation mode\n",
    "        print(f\"Loaded model: {model_name}\")\n",
    "        return tokenizer, model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {model_name}: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings\n",
    "def get_embeddings(smiles_list, tokenizer, model):\n",
    "    embeddings = []\n",
    "    \n",
    "    for smiles in smiles_list:\n",
    "        tokens = tokenizer(smiles, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            output = model(**tokens).last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "        embeddings.append(output)\n",
    "    \n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"flavor_output_embeddings\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fart_test...\n",
      "Extracting embeddings using ChemBERTa_Base...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model: seyonec/SMILES_tokenized_PubChem_shard00_160k\n",
      "Extracting embeddings using MolFormer_Base...\n",
      "Loaded model: ibm-research/MoLFormer-XL-both-10pct\n",
      "Saved: flavor_output_embeddings/fart_test_embed.csv\n",
      "Processing fart_eval...\n",
      "Extracting embeddings using ChemBERTa_Base...\n",
      "Loaded model: seyonec/SMILES_tokenized_PubChem_shard00_160k\n",
      "Extracting embeddings using MolFormer_Base...\n",
      "Loaded model: ibm-research/MoLFormer-XL-both-10pct\n",
      "Saved: flavor_output_embeddings/fart_eval_embed.csv\n",
      "Processing fart_train...\n",
      "Extracting embeddings using ChemBERTa_Base...\n",
      "Loaded model: seyonec/SMILES_tokenized_PubChem_shard00_160k\n",
      "Extracting embeddings using MolFormer_Base...\n",
      "Loaded model: ibm-research/MoLFormer-XL-both-10pct\n",
      "Saved: flavor_output_embeddings/fart_train_embed.csv\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, df in datasets.items():\n",
    "    print(f\"Processing {dataset_name}...\")\n",
    "\n",
    "    for model_name, model_info in models_info.items():\n",
    "        print(f\"Extracting embeddings using {model_name}...\")\n",
    "\n",
    "        tokenizer, model = load_model(model_info[\"model\"])\n",
    "        if not tokenizer or not model:\n",
    "            continue \n",
    "\n",
    "        embeddings = get_embeddings(df[\"Canonicalized SMILES\"].tolist(), tokenizer, model)\n",
    "\n",
    "        df[model_name + \"_embeddings\"] = [\",\".join(map(str, emb)) for emb in embeddings]\n",
    "\n",
    "    output_path = os.path.join(output_dir, f\"{dataset_name}_embed.csv\")\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Canonicalized SMILES</th>\n",
       "      <th>Standardized SMILES</th>\n",
       "      <th>Canonicalized Taste</th>\n",
       "      <th>Original Labels</th>\n",
       "      <th>Source</th>\n",
       "      <th>is_multiclass</th>\n",
       "      <th>Embeddings</th>\n",
       "      <th>ChemBERTa_Base_embeddings</th>\n",
       "      <th>MolFormer_Base_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>COC(=O)c1cccc(CCc2ccc(OC)c(O)c2)c1</td>\n",
       "      <td>COC(=O)c1cccc(CCc2ccc(OC)c(O)c2)c1</td>\n",
       "      <td>undefined</td>\n",
       "      <td>Tasteless, Tastelessness</td>\n",
       "      <td>chemtastes_db</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 4.23220634e-01 -3.61322016e-01  1.36605442e-...</td>\n",
       "      <td>0.42322063,-0.36132202,0.13660544,-0.5751529,0...</td>\n",
       "      <td>0.57139325,0.5010865,0.95544285,-0.108787954,-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CCCCCC(=Cc1ccccc1)COC(=O)CC(C)C</td>\n",
       "      <td>CCCCCC(=Cc1ccccc1)COC(=O)CC(C)C</td>\n",
       "      <td>undefined</td>\n",
       "      <td>oily, tobacco, fruity</td>\n",
       "      <td>flavor_db</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 9.82137978e-01 -3.90844733e-01  4.28043664e-...</td>\n",
       "      <td>0.982138,-0.39084473,0.42804366,0.51905835,-0....</td>\n",
       "      <td>0.8856047,-0.027730905,0.56260943,0.34591734,-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CC=C(C)C(CCC(C)CCCC(C)C(C)CCC(C)C)OC1C(CO)OC(O...</td>\n",
       "      <td>CC=C(C)C(CCC(C)CCCC(C)C(C)CCC(C)C)OC1C(CO)OC(O...</td>\n",
       "      <td>sweet</td>\n",
       "      <td>sweet-like</td>\n",
       "      <td>flavor_db</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 4.26222205e-01 -6.78874791e-01  5.00504911e-...</td>\n",
       "      <td>0.4262222,-0.6788748,0.5005049,0.28885567,-0.3...</td>\n",
       "      <td>0.67635477,0.008468097,0.83730954,0.34545955,-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CCC(C)C(N)C(=O)NC(Cc1ccccc1)C(=O)NC(CC(=O)O)C(...</td>\n",
       "      <td>CCC(C)C(N)C(=O)NC(Cc1ccccc1)C(=O)NC(CC(=O)O)C(...</td>\n",
       "      <td>sweet</td>\n",
       "      <td>sweet</td>\n",
       "      <td>flavor_db</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 5.21623552e-01 -5.82899749e-01  3.38670701e-...</td>\n",
       "      <td>0.52162355,-0.58289975,0.3386707,1.0003636,-0....</td>\n",
       "      <td>-0.47565556,0.79714537,0.53887177,0.50379896,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CCOC1OC(CO)C(O)C(OC2OC(CO)C(O)C(O)C2O)C1O</td>\n",
       "      <td>CCOC1OC(CO)C(O)C(OC2OC(CO)C(O)C(O)C2O)C1O</td>\n",
       "      <td>sweet</td>\n",
       "      <td>sweet-like</td>\n",
       "      <td>flavor_db</td>\n",
       "      <td>0</td>\n",
       "      <td>[-8.61615717e-01 -5.76748490e-01  3.75833988e-...</td>\n",
       "      <td>-0.8616157,-0.5767485,0.375834,0.09298423,-0.9...</td>\n",
       "      <td>1.0611067,-0.0151342545,0.060202017,0.7335563,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                               Canonicalized SMILES  \\\n",
       "0           0                 COC(=O)c1cccc(CCc2ccc(OC)c(O)c2)c1   \n",
       "1           1                    CCCCCC(=Cc1ccccc1)COC(=O)CC(C)C   \n",
       "2           2  CC=C(C)C(CCC(C)CCCC(C)C(C)CCC(C)C)OC1C(CO)OC(O...   \n",
       "3           3  CCC(C)C(N)C(=O)NC(Cc1ccccc1)C(=O)NC(CC(=O)O)C(...   \n",
       "4           4          CCOC1OC(CO)C(O)C(OC2OC(CO)C(O)C(O)C2O)C1O   \n",
       "\n",
       "                                 Standardized SMILES Canonicalized Taste  \\\n",
       "0                 COC(=O)c1cccc(CCc2ccc(OC)c(O)c2)c1           undefined   \n",
       "1                    CCCCCC(=Cc1ccccc1)COC(=O)CC(C)C           undefined   \n",
       "2  CC=C(C)C(CCC(C)CCCC(C)C(C)CCC(C)C)OC1C(CO)OC(O...               sweet   \n",
       "3  CCC(C)C(N)C(=O)NC(Cc1ccccc1)C(=O)NC(CC(=O)O)C(...               sweet   \n",
       "4          CCOC1OC(CO)C(O)C(OC2OC(CO)C(O)C(O)C2O)C1O               sweet   \n",
       "\n",
       "            Original Labels         Source  is_multiclass  \\\n",
       "0  Tasteless, Tastelessness  chemtastes_db              0   \n",
       "1     oily, tobacco, fruity      flavor_db              0   \n",
       "2                sweet-like      flavor_db              0   \n",
       "3                     sweet      flavor_db              0   \n",
       "4                sweet-like      flavor_db              0   \n",
       "\n",
       "                                          Embeddings  \\\n",
       "0  [ 4.23220634e-01 -3.61322016e-01  1.36605442e-...   \n",
       "1  [ 9.82137978e-01 -3.90844733e-01  4.28043664e-...   \n",
       "2  [ 4.26222205e-01 -6.78874791e-01  5.00504911e-...   \n",
       "3  [ 5.21623552e-01 -5.82899749e-01  3.38670701e-...   \n",
       "4  [-8.61615717e-01 -5.76748490e-01  3.75833988e-...   \n",
       "\n",
       "                           ChemBERTa_Base_embeddings  \\\n",
       "0  0.42322063,-0.36132202,0.13660544,-0.5751529,0...   \n",
       "1  0.982138,-0.39084473,0.42804366,0.51905835,-0....   \n",
       "2  0.4262222,-0.6788748,0.5005049,0.28885567,-0.3...   \n",
       "3  0.52162355,-0.58289975,0.3386707,1.0003636,-0....   \n",
       "4  -0.8616157,-0.5767485,0.375834,0.09298423,-0.9...   \n",
       "\n",
       "                           MolFormer_Base_embeddings  \n",
       "0  0.57139325,0.5010865,0.95544285,-0.108787954,-...  \n",
       "1  0.8856047,-0.027730905,0.56260943,0.34591734,-...  \n",
       "2  0.67635477,0.008468097,0.83730954,0.34545955,-...  \n",
       "3  -0.47565556,0.79714537,0.53887177,0.50379896,0...  \n",
       "4  1.0611067,-0.0151342545,0.060202017,0.7335563,...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/raghvendra2/Molformer_Finetuning/flavor_output_embeddings/fart_train_embed.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Canonicalized SMILES</th>\n",
       "      <th>Standardized SMILES</th>\n",
       "      <th>Canonicalized Taste</th>\n",
       "      <th>Original Labels</th>\n",
       "      <th>Source</th>\n",
       "      <th>is_multiclass</th>\n",
       "      <th>Embeddings</th>\n",
       "      <th>ChemBERTa_Base_embeddings</th>\n",
       "      <th>MolFormer_Base_embeddings</th>\n",
       "      <th>RDKit_Features</th>\n",
       "      <th>PubChem_Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>683</td>\n",
       "      <td>C=C1CC23CCC4C(C)(C(=O)O)CCCC4(C)C2CCC1(O)C3</td>\n",
       "      <td>C=C1CC23CCC4C(C)(C(=O)O)CCCC4(C)C2CCC1(O)C3</td>\n",
       "      <td>sweet</td>\n",
       "      <td>Sweet, Sweetness</td>\n",
       "      <td>chemtastes_db</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 7.68807650e-01 -5.76021433e-01  5.22678196e-...</td>\n",
       "      <td>[ 7.68807650e-01 -5.76021430e-01  5.22678200e-...</td>\n",
       "      <td>[ 5.54604600e-01 -2.52589300e-01  1.67957400e-...</td>\n",
       "      <td>[12.03983746430671, 12.03983746430671, 0.10673...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11595</td>\n",
       "      <td>COc1ccc(C2Oc3cc(O)cc(O)c3C(=O)C2OC2OC(COC3OC(C...</td>\n",
       "      <td>COc1ccc(C2Oc3cc(O)cc(O)c3C(=O)C2OC2OC(COC3OC(C...</td>\n",
       "      <td>sweet</td>\n",
       "      <td>sweet-like</td>\n",
       "      <td>flavor_db</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.37687132e-01 -5.83282530e-01  4.27158654e-...</td>\n",
       "      <td>[-1.37687130e-01 -5.83282530e-01  4.27158650e-...</td>\n",
       "      <td>[ 9.43758960e-01 -1.73485620e-01  7.99534100e-...</td>\n",
       "      <td>[13.708723535782834, 13.708723535782834, 0.109...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3891</td>\n",
       "      <td>CCOc1ccc(N)cc1[N+](=O)[O-]</td>\n",
       "      <td>CCOc1ccc(N)cc1[N+](=O)[O-]</td>\n",
       "      <td>sweet</td>\n",
       "      <td>sweet-like</td>\n",
       "      <td>flavor_db</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 0.88360196 -0.43877032 -0.33330277  0.079518...</td>\n",
       "      <td>[ 0.88360196 -0.43877032 -0.33330277  0.079518...</td>\n",
       "      <td>[ 3.78544600e-01  2.11703670e-01  4.95371040e-...</td>\n",
       "      <td>[10.51880007558579, 10.51880007558579, 0.09550...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8594</td>\n",
       "      <td>CCCOP(=O)(O)OP(=O)(O)OP(=O)(O)OCC1OC(n2cnc3c(N...</td>\n",
       "      <td>CCCOP(=O)(O)OP(=O)(O)OP(=O)(O)OCC1OC(n2cnc3c(N...</td>\n",
       "      <td>sweet</td>\n",
       "      <td>sweet-like</td>\n",
       "      <td>flavor_db</td>\n",
       "      <td>0</td>\n",
       "      <td>[-4.16371375e-01 -4.88543302e-01 -1.55383557e-...</td>\n",
       "      <td>[-4.16371380e-01 -4.88543300e-01 -1.55383560e-...</td>\n",
       "      <td>[ 6.93409440e-01  3.03417440e-01  2.26749000e-...</td>\n",
       "      <td>[12.037809034783692, 12.037809034783692, 0.053...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6577</td>\n",
       "      <td>CCC(C)C(NC(=O)C(Cc1ccccc1)NC(=O)C(C)NC(=O)C(N)...</td>\n",
       "      <td>CCC(C)C(NC(=O)C(Cc1ccccc1)NC(=O)C(C)NC(=O)C(N)...</td>\n",
       "      <td>sweet</td>\n",
       "      <td>sweet</td>\n",
       "      <td>flavor_db</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 6.56488776e-01 -8.65771413e-01  4.55688894e-...</td>\n",
       "      <td>[ 6.56488800e-01 -8.65771400e-01  4.55688900e-...</td>\n",
       "      <td>[-5.84631700e-01  7.86514000e-01  4.75675640e-...</td>\n",
       "      <td>[12.930864686426554, 12.930864686426554, 0.087...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                               Canonicalized SMILES  \\\n",
       "0         683        C=C1CC23CCC4C(C)(C(=O)O)CCCC4(C)C2CCC1(O)C3   \n",
       "1       11595  COc1ccc(C2Oc3cc(O)cc(O)c3C(=O)C2OC2OC(COC3OC(C...   \n",
       "2        3891                         CCOc1ccc(N)cc1[N+](=O)[O-]   \n",
       "3        8594  CCCOP(=O)(O)OP(=O)(O)OP(=O)(O)OCC1OC(n2cnc3c(N...   \n",
       "4        6577  CCC(C)C(NC(=O)C(Cc1ccccc1)NC(=O)C(C)NC(=O)C(N)...   \n",
       "\n",
       "                                 Standardized SMILES Canonicalized Taste  \\\n",
       "0        C=C1CC23CCC4C(C)(C(=O)O)CCCC4(C)C2CCC1(O)C3               sweet   \n",
       "1  COc1ccc(C2Oc3cc(O)cc(O)c3C(=O)C2OC2OC(COC3OC(C...               sweet   \n",
       "2                         CCOc1ccc(N)cc1[N+](=O)[O-]               sweet   \n",
       "3  CCCOP(=O)(O)OP(=O)(O)OP(=O)(O)OCC1OC(n2cnc3c(N...               sweet   \n",
       "4  CCC(C)C(NC(=O)C(Cc1ccccc1)NC(=O)C(C)NC(=O)C(N)...               sweet   \n",
       "\n",
       "    Original Labels         Source  is_multiclass  \\\n",
       "0  Sweet, Sweetness  chemtastes_db              0   \n",
       "1        sweet-like      flavor_db              0   \n",
       "2        sweet-like      flavor_db              0   \n",
       "3        sweet-like      flavor_db              0   \n",
       "4             sweet      flavor_db              0   \n",
       "\n",
       "                                          Embeddings  \\\n",
       "0  [ 7.68807650e-01 -5.76021433e-01  5.22678196e-...   \n",
       "1  [-1.37687132e-01 -5.83282530e-01  4.27158654e-...   \n",
       "2  [ 0.88360196 -0.43877032 -0.33330277  0.079518...   \n",
       "3  [-4.16371375e-01 -4.88543302e-01 -1.55383557e-...   \n",
       "4  [ 6.56488776e-01 -8.65771413e-01  4.55688894e-...   \n",
       "\n",
       "                           ChemBERTa_Base_embeddings  \\\n",
       "0  [ 7.68807650e-01 -5.76021430e-01  5.22678200e-...   \n",
       "1  [-1.37687130e-01 -5.83282530e-01  4.27158650e-...   \n",
       "2  [ 0.88360196 -0.43877032 -0.33330277  0.079518...   \n",
       "3  [-4.16371380e-01 -4.88543300e-01 -1.55383560e-...   \n",
       "4  [ 6.56488800e-01 -8.65771400e-01  4.55688900e-...   \n",
       "\n",
       "                           MolFormer_Base_embeddings  \\\n",
       "0  [ 5.54604600e-01 -2.52589300e-01  1.67957400e-...   \n",
       "1  [ 9.43758960e-01 -1.73485620e-01  7.99534100e-...   \n",
       "2  [ 3.78544600e-01  2.11703670e-01  4.95371040e-...   \n",
       "3  [ 6.93409440e-01  3.03417440e-01  2.26749000e-...   \n",
       "4  [-5.84631700e-01  7.86514000e-01  4.75675640e-...   \n",
       "\n",
       "                                      RDKit_Features  PubChem_Features  \n",
       "0  [12.03983746430671, 12.03983746430671, 0.10673...               NaN  \n",
       "1  [13.708723535782834, 13.708723535782834, 0.109...               NaN  \n",
       "2  [10.51880007558579, 10.51880007558579, 0.09550...               NaN  \n",
       "3  [12.037809034783692, 12.037809034783692, 0.053...               NaN  \n",
       "4  [12.930864686426554, 12.930864686426554, 0.087...               NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "file = pd.read_csv(\"/home/raghvendra2/Molformer_Finetuning/classification_model_flavor/test_with_features.csv\")\n",
    "\n",
    "file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/qnap_home/raghvendra2/micromamba/envs/Molformer/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = {\n",
    "    \"fart_test\": \"/home/raghvendra2/Molformer_Finetuning/fart_test.csv\",\n",
    "    \"fart_eval\": \"/home/raghvendra2/Molformer_Finetuning/fart_val.csv\",\n",
    "    \"fart_train\": \"/home/raghvendra2/Molformer_Finetuning/fart_train.csv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {name: pd.read_csv(path) for name, path in file_paths.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configurations of additional ChemBERTa final models \n",
    "models_info = {\n",
    "    \"ChemBERTa_Base\": {\n",
    "        \"tokenizer\": \"seyonec/SMILES_tokenized_PubChem_shard00_160k\",\n",
    "        \"model\": \"seyonec/SMILES_tokenized_PubChem_shard00_160k\"\n",
    "    },\n",
    "    \"MolFormer_Base\": {\n",
    "        \"tokenizer\": \"ibm-research/MoLFormer-XL-both-10pct\",\n",
    "        \"model\": \"ibm-research/MoLFormer-XL-both-10pct\"\n",
    "    },\n",
    "    \"ChemBERTa_Finetuned\": {\n",
    "        \"tokenizer\": \"seyonec/SMILES_tokenized_PubChem_shard00_160k\",\n",
    "        \"model\": \"/home/raghvendra2/Molformer_Finetuning/Chemberta_Lora_finetuned_flavor_model\",\n",
    "        \"num_labels\": 5\n",
    "    },\n",
    "    \"MolFormer_Finetuned\": {\n",
    "        \"tokenizer\": \"ibm-research/MoLFormer-XL-both-10pct\",\n",
    "        \"model\": \"/home/raghvendra2/Molformer_Finetuning/Molformer_Lora_Finetuned_flavor_model2\",\n",
    "        \"num_labels\": 5\n",
    "    },\n",
    "    \"ChemBERTa_77M_MTR\": {\n",
    "        \"tokenizer\": \"DeepChem/ChemBERTa-77M-MTR\",\n",
    "        \"model\": \"/home/raghvendra2/Molformer_Finetuning/chemberta_final_model_lora_100M_MTR\",\n",
    "        \"num_labels\": 5\n",
    "    },\n",
    "    \"ChemBERTa_10M_MTR\": {\n",
    "        \"tokenizer\": \"DeepChem/ChemBERTa-10M-MTR\",\n",
    "        \"model\": \"/home/raghvendra2/Molformer_Finetuning/chemberta_final_model_lora_10M_MTR\",\n",
    "        \"num_labels\": 5\n",
    "    },\n",
    "    \"ChemBERTa_77M_MLM\": {\n",
    "        \"tokenizer\": \"DeepChem/ChemBERTa-77M-MLM\",\n",
    "        \"model\": \"/home/raghvendra2/Molformer_Finetuning/chemberta_final_model_lora_77M_MLM\",\n",
    "        \"num_labels\": 5\n",
    "    },\n",
    "    \"ChemBERTa_10M_MLM\": {\n",
    "        \"tokenizer\": \"DeepChem/ChemBERTa-10M-MLM\",\n",
    "        \"model\": \"/home/raghvendra2/Molformer_Finetuning/chemberta_final_model_lora_10M_MLM\",\n",
    "        \"num_labels\": 5\n",
    "    },\n",
    "    \"ChemBERTa_5M_MTR\": {\n",
    "        \"tokenizer\": \"DeepChem/ChemBERTa-5M-MTR\",\n",
    "        \"model\": \"/home/raghvendra2/Molformer_Finetuning/chemberta_final_model_lora_5M_MTR\",\n",
    "        \"num_labels\": 5\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_info):\n",
    "    \"\"\"Load model and tokenizer. Choose appropriate class based on whether it's a classification model.\"\"\"\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_info[\"tokenizer\"], trust_remote_code=True\n",
    "        )\n",
    "\n",
    "        if \"num_labels\" in model_info:\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(\n",
    "                model_info[\"model\"],\n",
    "                num_labels=model_info[\"num_labels\"],\n",
    "                trust_remote_code=True\n",
    "            )\n",
    "        else:\n",
    "            model = AutoModel.from_pretrained(\n",
    "                model_info[\"model\"],\n",
    "                trust_remote_code=True\n",
    "            )\n",
    "\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        print(f\"Loaded model: {model_info['model']}\")\n",
    "        return tokenizer, model\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {model_info['model']}: {e}\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(smiles_list, tokenizer, model):\n",
    "    embeddings = []\n",
    "    \n",
    "    for smiles in smiles_list:\n",
    "        tokens = tokenizer(smiles, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        tokens = {k: v.to(device) for k, v in tokens.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Extract embeddings from base model (ignoring classification head)\n",
    "            if hasattr(model, \"roberta\"):\n",
    "                output = model.roberta(**tokens).last_hidden_state.mean(dim=1)\n",
    "            elif hasattr(model, \"bert\"):\n",
    "                output = model.bert(**tokens).last_hidden_state.mean(dim=1)\n",
    "            elif hasattr(model, \"base_model\"):\n",
    "                output = model.base_model(**tokens).last_hidden_state.mean(dim=1)\n",
    "            else:\n",
    "                raise ValueError(\"Unknown model architecture!\")\n",
    "                \n",
    "        embeddings.append(output.squeeze().cpu().numpy())\n",
    "\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/home/raghvendra2/Molformer_Finetuning/flavor_output_embeddings/all_models\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fart_test...\n",
      "Extracting embeddings using ChemBERTa_Base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 06:09:51.607939: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-11 06:09:51.627573: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744344591.652746 1982895 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744344591.660434 1982895 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744344591.679367 1982895 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744344591.679384 1982895 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744344591.679387 1982895 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744344591.679389 1982895 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-11 06:09:51.685222: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model: seyonec/SMILES_tokenized_PubChem_shard00_160k\n",
      "Extracting embeddings using MolFormer_Base...\n",
      "Loaded model: ibm-research/MoLFormer-XL-both-10pct\n",
      "Extracting embeddings using ChemBERTa_Finetuned...\n",
      "Loaded model: /home/raghvendra2/Molformer_Finetuning/Chemberta_Lora_finetuned_flavor_model\n",
      "Extracting embeddings using MolFormer_Finetuned...\n",
      "Loaded model: /home/raghvendra2/Molformer_Finetuning/Molformer_Lora_Finetuned_flavor_model2\n",
      "Extracting embeddings using ChemBERTa_77M_MTR...\n",
      "Loaded model: /home/raghvendra2/Molformer_Finetuning/chemberta_final_model_lora_100M_MTR\n",
      "Extracting embeddings using ChemBERTa_10M_MTR...\n",
      "Loaded model: /home/raghvendra2/Molformer_Finetuning/chemberta_final_model_lora_10M_MTR\n",
      "Extracting embeddings using ChemBERTa_77M_MLM...\n",
      "Loaded model: /home/raghvendra2/Molformer_Finetuning/chemberta_final_model_lora_77M_MLM\n",
      "Extracting embeddings using ChemBERTa_10M_MLM...\n",
      "Loaded model: /home/raghvendra2/Molformer_Finetuning/chemberta_final_model_lora_10M_MLM\n",
      "Extracting embeddings using ChemBERTa_5M_MTR...\n",
      "Loaded model: /home/raghvendra2/Molformer_Finetuning/chemberta_final_model_lora_5M_MTR\n",
      "Saved: /home/raghvendra2/Molformer_Finetuning/flavor_output_embeddings/all_models/fart_test_embed.csv\n",
      "Processing fart_eval...\n",
      "Extracting embeddings using ChemBERTa_Base...\n",
      "Loaded model: seyonec/SMILES_tokenized_PubChem_shard00_160k\n",
      "Extracting embeddings using MolFormer_Base...\n",
      "Loaded model: ibm-research/MoLFormer-XL-both-10pct\n",
      "Extracting embeddings using ChemBERTa_Finetuned...\n",
      "Loaded model: /home/raghvendra2/Molformer_Finetuning/Chemberta_Lora_finetuned_flavor_model\n",
      "Extracting embeddings using MolFormer_Finetuned...\n",
      "Loaded model: /home/raghvendra2/Molformer_Finetuning/Molformer_Lora_Finetuned_flavor_model2\n",
      "Extracting embeddings using ChemBERTa_77M_MTR...\n",
      "Loaded model: /home/raghvendra2/Molformer_Finetuning/chemberta_final_model_lora_100M_MTR\n",
      "Extracting embeddings using ChemBERTa_10M_MTR...\n",
      "Loaded model: /home/raghvendra2/Molformer_Finetuning/chemberta_final_model_lora_10M_MTR\n",
      "Extracting embeddings using ChemBERTa_77M_MLM...\n",
      "Loaded model: /home/raghvendra2/Molformer_Finetuning/chemberta_final_model_lora_77M_MLM\n",
      "Extracting embeddings using ChemBERTa_10M_MLM...\n",
      "Loaded model: /home/raghvendra2/Molformer_Finetuning/chemberta_final_model_lora_10M_MLM\n",
      "Extracting embeddings using ChemBERTa_5M_MTR...\n",
      "Loaded model: /home/raghvendra2/Molformer_Finetuning/chemberta_final_model_lora_5M_MTR\n",
      "Saved: /home/raghvendra2/Molformer_Finetuning/flavor_output_embeddings/all_models/fart_eval_embed.csv\n",
      "Processing fart_train...\n",
      "Extracting embeddings using ChemBERTa_Base...\n",
      "Loaded model: seyonec/SMILES_tokenized_PubChem_shard00_160k\n",
      "Extracting embeddings using MolFormer_Base...\n",
      "Loaded model: ibm-research/MoLFormer-XL-both-10pct\n",
      "Extracting embeddings using ChemBERTa_Finetuned...\n",
      "Loaded model: /home/raghvendra2/Molformer_Finetuning/Chemberta_Lora_finetuned_flavor_model\n",
      "Extracting embeddings using MolFormer_Finetuned...\n",
      "Loaded model: /home/raghvendra2/Molformer_Finetuning/Molformer_Lora_Finetuned_flavor_model2\n",
      "Extracting embeddings using ChemBERTa_77M_MTR...\n",
      "Loaded model: /home/raghvendra2/Molformer_Finetuning/chemberta_final_model_lora_100M_MTR\n",
      "Extracting embeddings using ChemBERTa_10M_MTR...\n",
      "Loaded model: /home/raghvendra2/Molformer_Finetuning/chemberta_final_model_lora_10M_MTR\n",
      "Extracting embeddings using ChemBERTa_77M_MLM...\n",
      "Loaded model: /home/raghvendra2/Molformer_Finetuning/chemberta_final_model_lora_77M_MLM\n",
      "Extracting embeddings using ChemBERTa_10M_MLM...\n",
      "Loaded model: /home/raghvendra2/Molformer_Finetuning/chemberta_final_model_lora_10M_MLM\n",
      "Extracting embeddings using ChemBERTa_5M_MTR...\n",
      "Loaded model: /home/raghvendra2/Molformer_Finetuning/chemberta_final_model_lora_5M_MTR\n",
      "Saved: /home/raghvendra2/Molformer_Finetuning/flavor_output_embeddings/all_models/fart_train_embed.csv\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, df in datasets.items():\n",
    "    print(f\"Processing {dataset_name}...\")\n",
    "\n",
    "    for model_name, model_info in models_info.items():\n",
    "        print(f\"Extracting embeddings using {model_name}...\")\n",
    "\n",
    "        tokenizer, model = load_model(model_info)\n",
    "        if not tokenizer or not model:\n",
    "            continue \n",
    "\n",
    "        embeddings = get_embeddings(df[\"Canonicalized SMILES\"].tolist(), tokenizer, model)\n",
    "\n",
    "        df[model_name + \"_embeddings\"] = [\",\".join(map(str, emb)) for emb in embeddings]\n",
    "\n",
    "    output_path = os.path.join(output_dir, f\"{dataset_name}_embed.csv\")\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names:\n",
      "['Unnamed: 0', 'Canonicalized SMILES', 'Standardized SMILES', 'Canonicalized Taste', 'Original Labels', 'Source', 'is_multiclass', 'ChemBERTa_Base_embeddings', 'MolFormer_Base_embeddings', 'ChemBERTa_Finetuned_embeddings', 'MolFormer_Finetuned_embeddings', 'ChemBERTa_77M_MTR_embeddings', 'ChemBERTa_10M_MTR_embeddings', 'ChemBERTa_77M_MLM_embeddings', 'ChemBERTa_10M_MLM_embeddings', 'ChemBERTa_5M_MTR_embeddings']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"/home/raghvendra2/Molformer_Finetuning/flavor_output_embeddings/all_models/fart_train_embed.csv\"\n",
    "df = pd.read_csv(file_path, nrows=5)\n",
    "\n",
    "print(\"Column names:\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
