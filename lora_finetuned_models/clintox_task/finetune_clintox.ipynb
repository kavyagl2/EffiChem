{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53a6e90a",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee34a236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import wandb\n",
    "import evaluate\n",
    "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from evaluate import load\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.special import softmax\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score,matthews_corrcoef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045a8c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load():\n",
    "    train_clin=pd.read_csv('.../clintox_train.csv')\n",
    "    val_clin=pd.read_csv('.../clintox_valid.csv')\n",
    "\n",
    "    return train_clin, val_clin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48619489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(data_process,tokenizer_clin):\n",
    "\n",
    "    smiles_list_clin = data_process['smiles'].tolist()\n",
    "    tokenized_clin=tokenizer_clin(smiles_list_clin)\n",
    "    \n",
    "    \n",
    "    dataset_clin = Dataset.from_dict(tokenized_clin)\n",
    "    \n",
    "\n",
    "    labels_clin = data_process['CT_TOX'].tolist() \n",
    "    \n",
    "    dataset_clin = dataset_clin.add_column(\"labels\", labels_clin)\n",
    "    \n",
    "\n",
    "    return dataset_clin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11586cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "\n",
    "def lora_config():\n",
    "\n",
    "    lora_config = LoraConfig(\n",
    "        task_type=\"SEQ_CLS\",  # Sequence classification task\n",
    "        r=32,  # Rank of LoRA matrices\n",
    "        lora_alpha=16,  # Scaling factor double of rank( from the rule of thumb)\n",
    "        target_modules='all-linear',\n",
    "        lora_dropout=0.1  # Dropout rate\n",
    "        #init_lora_weights=\"gaussian\"\n",
    "    )\n",
    "\n",
    "    return lora_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b085085a",
   "metadata": {},
   "source": [
    "## Weighted Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a54a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_weights_calculation(train_dataset):\n",
    "\n",
    "        # Calculate class weights based on the distribution of labels\n",
    "        class_weights = [1 - (train_dataset['labels'].count(0) / len(train_dataset['labels'])),\n",
    "                        1 - (train_dataset['labels'].count(1) / len(train_dataset['labels']))]\n",
    "        return torch.from_numpy(np.array(class_weights)).float()\n",
    "\n",
    "\n",
    "class WeightedLossTrainer(Trainer):\n",
    "   \n",
    "    def compute_loss(self, model, inputs,train_dataset, return_outputs=False, num_items_in_batch=None):\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "\n",
    "        # Extract labels\n",
    "        labels = inputs.get(\"labels\")\n",
    "        \n",
    "        class_weights= class_weights_calculation(train_dataset)\n",
    "        # compute custom loss (suppose one has 2 labels with different weights)\n",
    "        loss_func = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "        # compute loss\n",
    "        loss = loss_func(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2c7ce7",
   "metadata": {},
   "source": [
    "## Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbb6eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def focal_loss(inputs, targets, alpha=1, gamma=2):\n",
    "    log_prob = F.log_softmax(inputs, dim=-1)\n",
    "    prob = torch.exp(log_prob)  # Convert log probabilities back to normal probabilities\n",
    "\n",
    "    targets_one_hot = F.one_hot(targets, num_classes=inputs.shape[-1])\n",
    "    pt = torch.sum(prob * targets_one_hot, dim=-1)  # Get probability of the true class\n",
    "\n",
    "    focal_loss = -alpha * (1 - pt) ** gamma * torch.sum(log_prob * targets_one_hot, dim=-1)\n",
    "    \n",
    "    return focal_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3965f701",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None,**kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss = focal_loss(logits, labels)\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0b43fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "sweep_config = {\n",
    "\"name\": \"Flavor Hyperparameter Tuning\",\n",
    "\"method\": \"bayes\",\n",
    "\"metric\": {\n",
    "    \"goal\": \"maximize\", \n",
    "    \"name\": \"eval/mcc_metric\"},\n",
    "\"parameters\": {\"lr\": {\n",
    "        \"distribution\": \"uniform\",\n",
    "        \"min\": 1e-5,  \n",
    "        \"max\": 2e-3},\n",
    "    \"r\": {\"values\": [4,8,16,32,64, 128]},\n",
    "    \"lora_alpha\": {\"values\": [4,8,16,32,64,128]},\n",
    "    \"dropout\": {\"values\": [0.0,0.1,0.2] },\n",
    "    \n",
    "    \"optimizer\": {\"value\": [\"adamw\"]}}\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"huggingface\")\n",
    "\n",
    "model_list= [\"DeepChem/ChemBERTa-77M-MLM\",\n",
    "             \"DeepChem/ChemBERTa-10M-MLM\",\n",
    "             \"DeepChem/ChemBERTa-10M-MTR\",\n",
    "             \"DeepChem/ChemBERTa-5M-MTR\",\n",
    "             \"DeepChem/ChemBERTa-77M-MTR\",\n",
    "             \"ibm/MoLFormer-XL-both-10pct\"]\n",
    "\n",
    "for model_name in model_list:\n",
    "    print(f\"Running sweep for model: {model_name}\")\n",
    "    \n",
    "    def safe_model_name(name1):\n",
    "        return re.sub(r\"[^a-zA-Z0-9]\", \"__\", name1)\n",
    "\n",
    "\n",
    "    def run_training():\n",
    "        print(f\"Running training for model: {model_name}\")\n",
    "        # Initialize W&B with sweep\n",
    "        run = wandb.init(project=\"clintox focal loss Hyperparameter Tuning\")\n",
    "        config = run.config\n",
    "\n",
    "        model_id_clean = safe_model_name(model_name)\n",
    "        print(f\"Model ID cleaned: {model_id_clean}\")\n",
    "        run_id = wandb.run.id\n",
    "\n",
    "        # Define unique output folders\n",
    "        save_dir = f\".../{model_id_clean}/{run_id}\"\n",
    "        logging_dir = f\".../{model_id_clean}/{run_id}\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        # Load tokenizer and model\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name,trust_remote_code=True)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=2,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "\n",
    "        # Load and preprocess data\n",
    "\n",
    "        train_data, val_data = data_load()\n",
    "        training_data = data_prep(train_data, tokenizer)\n",
    "        validation_data = data_prep(val_data, tokenizer)\n",
    "\n",
    "        # Apply LoRA\n",
    "        peft_config = lora_config(config.r, config.lora_alpha, config.dropout)\n",
    "        lora_model = get_peft_model(model, peft_config)\n",
    "        lora_model.print_trainable_parameters()\n",
    "\n",
    "\n",
    "        # Define training args\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=save_dir,\n",
    "            eval_strategy=\"epoch\",\n",
    "            learning_rate=config.lr,\n",
    "            per_device_train_batch_size=32,\n",
    "            per_device_eval_batch_size=32,\n",
    "            num_train_epochs=10,\n",
    "            weight_decay=0.01,\n",
    "            save_strategy=\"epoch\",\n",
    "            logging_dir=logging_dir,\n",
    "            logging_strategy=\"steps\",\n",
    "            logging_steps=500,\n",
    "            report_to=\"wandb\",\n",
    "            save_total_limit=3,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"eval_mcc_metric\"\n",
    "        )\n",
    "\n",
    "        accuracy_metric = load(\"accuracy\")\n",
    "\n",
    "        def compute_metrics(eval_pred):\n",
    "            logits, labels = eval_pred\n",
    "            probabilities = softmax(logits, axis=1)[:, 1]\n",
    "            predictions = np.argmax(logits, axis=1)\n",
    "            mcc = matthews_corrcoef(labels, predictions)\n",
    "\n",
    "            return {\n",
    "                \"eval_mcc_metric\": mcc,\n",
    "                \"Accuracy\": accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"],\n",
    "                \"AUC-ROC\": roc_auc_score(labels, probabilities),\n",
    "                \"Precision\": precision_score(labels, predictions),\n",
    "                \"Recall\": recall_score(labels, predictions),\n",
    "                \"F1-score\": f1_score(labels, predictions)\n",
    "            }\n",
    "\n",
    "        # Train with weigted loss trainer\n",
    "        trainer = WeightedLossTrainer(\n",
    "            model=lora_model,\n",
    "            args=training_args,\n",
    "            train_dataset=training_data,\n",
    "            eval_dataset=validation_data,\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics=compute_metrics,\n",
    "            callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "        )\n",
    "        \n",
    "        '''\n",
    "        # train with focal loss trainer\n",
    "        trainer = FocalLossTrainer(\n",
    "            model=lora_model,\n",
    "            args=training_args,\n",
    "            train_dataset=training_data,\n",
    "            eval_dataset=validation_data,\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics=compute_metrics,\n",
    "            callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
    "        )'''\n",
    "\n",
    "        trainer.train()\n",
    "        trainer.save_model(save_dir)\n",
    "        print(f\"Model saved to {save_dir}\")\n",
    "        print(f\"Training completed for model: {model_name}\")\n",
    "        \n",
    "        wandb.finish()\n",
    "\n",
    "\n",
    "\n",
    "    wandb.agent(sweep_id, function=run_training, count=5)\n",
    "\n",
    "    api = wandb.Api()\n",
    "    sweep = api.sweep(f\"huggingface/{sweep_id}\")\n",
    "    print(sweep.runs[0].summary_metrics)\n",
    "\n",
    "    runs_with_rmse = [run for run in sweep.runs if 'eval/mcc_metric' in run.summary_metrics]\n",
    "    if runs_with_rmse:\n",
    "        # Sort by rmse in descending order (maximize)\n",
    "        best_run = sorted(runs_with_rmse, key=lambda run: run.summary_metrics['eval/mcc_metric'])[0]\n",
    "    else:\n",
    "        raise ValueError(\"No runs found with 'eval/mcc_metric' metric.\")\n",
    "\n",
    "    best_hyperparameters = best_run.config\n",
    "    print(f\"Best hyperparameters: {best_hyperparameters}\")\n",
    "    print(\"completed sweep for model: \",model_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5cfaf4",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c8f405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "accuracy_metric = load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        probabilities = softmax(logits, axis=1)[:, 1]  # Get probabilities for class 1\n",
    "        predictions = np.argmax(logits, axis=1)  # Choose the most likely class\n",
    "        mcc = matthews_corrcoef(labels, predictions)\n",
    "        \n",
    "        \n",
    "        return {\n",
    "            \"eval_mcc_metric\": mcc,\n",
    "            \"Accuracy\": accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"],\n",
    "            \"AUC-ROC\": roc_auc_score(labels, probabilities),  # AUC-ROC requires probabilities\n",
    "            \"Precision\": precision_score(labels, predictions),\n",
    "            \"Recall\": recall_score(labels, predictions),\n",
    "            \"F1-score\": f1_score(labels, predictions)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db1ac12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Map your folder names to the base HuggingFace model names\n",
    "MODEL_NAME_MAP = {\n",
    "    \"DeepChem__ChemBERTa__5M__MTR\": \"DeepChem/ChemBERTa-5M-MTR\",\n",
    "    \"DeepChem__ChemBERTa__10M__MTR\": \"DeepChem/ChemBERTa-10M-MTR\",\n",
    "    \"DeepChem__ChemBERTa__77M__MLM\": \"DeepChem/ChemBERTa-77M-MLM\",\n",
    "    \"DeepChem__ChemBERTa__10M__MLM\": \"DeepChem/ChemBERTa-10M-MLM\",\n",
    "    \"DeepChem__ChemBERTa__77M__MTR\": \"DeepChem/ChemBERTa-77M-MTR\",\n",
    "    \"ibm__MoLFormer__XL__both__10pct\": \"ibm/MoLFormer-XL-both-10pct\",\n",
    "       \n",
    "}\n",
    "\n",
    "test_data=pd.read_csv('clintox_dataset/test.csv')\n",
    "\n",
    "models_root_dir = \".../models_clin_chem_WL\" #add model saved path\n",
    "\n",
    "eval_args = TrainingArguments(\n",
    "    output_dir=\"./test_results_clin\",\n",
    "    per_device_eval_batch_size=16,\n",
    "    report_to=\"none\",  # Disable logging to W&B for test\n",
    "    disable_tqdm=True,  # disable progress bar\n",
    "  \n",
    "\n",
    ")\n",
    "\n",
    "def find_all_peft_checkpoints(root_dir):\n",
    "    checkpoints = []\n",
    "    for model_folder in os.listdir(root_dir):\n",
    "        model_folder_path = os.path.join(root_dir, model_folder)\n",
    "        if not os.path.isdir(model_folder_path):\n",
    "            continue\n",
    "        for run_id in os.listdir(model_folder_path):\n",
    "            run_path = os.path.join(model_folder_path, run_id)\n",
    "            if not os.path.isdir(run_path):\n",
    "                continue\n",
    "            for subdir in os.listdir(run_path):\n",
    "                checkpoint_path = os.path.join(run_path, subdir)\n",
    "                if subdir.startswith(\"checkpoint-\") and os.path.exists(os.path.join(checkpoint_path, \"adapter_config.json\")):\n",
    "                    checkpoints.append((model_folder, run_id, checkpoint_path))\n",
    "    return checkpoints\n",
    "\n",
    "valid_checkpoints = find_all_peft_checkpoints(models_root_dir)\n",
    "print(f\"Found {len(valid_checkpoints)} valid checkpoints.\")\n",
    "\n",
    "for model_folder, run_id, checkpoint_path in valid_checkpoints:\n",
    "    print(\"Model folder: \",model_folder)\n",
    "\n",
    "    hf_model_name = MODEL_NAME_MAP[model_folder]\n",
    "    print(f\"Using base model: {hf_model_name}\")\n",
    "    # Load tokenizer and base model for the model type\n",
    "    tokenizer = AutoTokenizer.from_pretrained(hf_model_name, trust_remote_code=True)\n",
    "    base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        hf_model_name,\n",
    "        num_labels=2,\n",
    "        problem_type=\"single_label_classification\",\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "\n",
    "    from datasets import Dataset\n",
    "\n",
    "    smiles_test = test_data['smiles'].tolist()\n",
    "\n",
    "    test_tokenized =tokenizer(smiles_test)\n",
    "\n",
    "    test_dataset = Dataset.from_dict(test_tokenized)\n",
    "\n",
    "    test_labels = test_data['CT_TOX'].tolist() \n",
    "\n",
    "\n",
    "    test_dataset = test_dataset.add_column(\"labels\", test_labels)\n",
    "\n",
    "    # Load the adapter checkpoint\n",
    "    adapter_model = PeftModel.from_pretrained(base_model, checkpoint_path)\n",
    "    adapter_model.eval()\n",
    "\n",
    "    # Eval\n",
    "    from transformers import Trainer\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=adapter_model,\n",
    "        args=eval_args,\n",
    "        eval_dataset=test_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    print(f\"\\n Evaluating {model_folder}/{run_id}/{os.path.basename(checkpoint_path)}\")\n",
    "    \n",
    "    test_results = trainer.evaluate()\n",
    "   \n",
    "    \n",
    "   \n",
    "\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3e0abe",
   "metadata": {},
   "source": [
    "## Load and Merge Base Model with LoRA weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7acb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"DeepChem/ChemBERTa-77M-MLM\", #change model name as per your requirement\n",
    "    num_labels=2,\n",
    "    problem_type=\"single_label_classification\",    \n",
    "    trust_remote_code=True,\n",
    "    \n",
    ")\n",
    "from peft import PeftModel  \n",
    "\n",
    "adapter_model = PeftModel.from_pretrained(base_model, \".../DeepChem__ChemBERTa__77M__MLM/x38bwbvz/checkpoint-416\")\n",
    "\n",
    "final_model_clintox_molformer= adapter_model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619c7975",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \".../weighted_loss_clin/final_model_chem_77M-MLM-WL\"\n",
    "\n",
    "final_model_clintox_molformer.save_pretrained(save_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
